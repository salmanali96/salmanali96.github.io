---
---

@string{aps = {American Physical Society,}}




@article{haider2025inr,
  abbr     = {arXiv},
  title    ={I-INR: Iterative Implicit Neural Representations},
  author   ={Haider, Ali* and Ali, Muhammad Salman* and Qamar, Maryam and Khalil, Tahir and Kim, Soo Ye and Oh, Jihyong and Tartaglione, Enzo and Bae, Sung-Ho},
  journal  ={Under Review (arXiv)},
  selected = {true},
  preview  ={i-inr.png},
  pdf      ={https://arxiv.org/abs/2504.17364},
  year     ={2025},
  abstract = {Implicit Neural Representations (INRs) have revolutionized signal processing and computer vision by modeling signals as continuous, differentiable functions parameterized by neural networks. However, their inherent formulation as a regression problem makes them prone to regression to the mean, limiting their ability to capture fine details, retain high-frequency information, and handle noise effectively. To address these challenges, we propose Iterative Implicit Neural Representations (I-INRs) a novel plug-and-play framework that enhances signal reconstruction through an iterative refinement process. I-INRs effectively recover high-frequency details, improve robustness to noise, and achieve superior reconstruction quality. Our framework seamlessly integrates with existing INR architectures, delivering substantial performance gains across various tasks. Extensive experiments show that I-INRs outperform baseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision applications such as image restoration, image denoising, and object occupancy prediction.}
}

@article{ali2025compression,
  abbr     = {arXiv},
  title={Compression in 3d gaussian splatting: A survey of methods, trends, and future directions},
  author={Muhammad Salman Ali and Zhang, Chaoning and Cagnazzo, Marco and Valenzise, Giuseppe and Tartaglione, Enzo and Bae, Sung-Ho},
  journal  = {Under Review (arXiv)},
  year={2025},
  selected = {true},
  preview={3dgs_survey.png},
  pdf={https://arxiv.org/abs/2502.19457},
  abstract={3D Gaussian Splatting (3DGS) has recently emerged as a pioneering approach in explicit scene rendering and computer graphics. Unlike traditional neural radiance field (NeRF) methods, which typically rely on implicit, coordinate-based models to map spatial coordinates to pixel values, 3DGS utilizes millions of learnable 3D Gaussians. Its differentiable rendering technique and inherent capability for explicit scene representation and manipulation positions 3DGS as a potential game-changer for the next generation of 3D reconstruction and representation technologies. This enables 3DGS to deliver real-time rendering speeds while offering unparalleled editability levels. However, despite its advantages, 3DGS suffers from substantial memory and storage requirements, posing challenges for deployment on resource-constrained devices. In this survey, we provide a comprehensive overview focusing on the scalability and compression of 3DGS. We begin with a detailed background overview of 3DGS, followed by a structured taxonomy of existing compression methods. Additionally, we analyze and compare current methods from the topological perspective, evaluating their strengths and limitations in terms of fidelity, compression ratios, and computational efficiency. Furthermore, we explore how advancements in efficient NeRF representations can inspire future developments in 3DGS optimization. Finally, we conclude with current research challenges and highlight key directions for future exploration.}

}

@article{ali2024elmgs,
  abbr = {WACV},
  title={ELMGS: Enhancing memory and computation scaLability through coMpression for 3D Gaussian Splatting},
  author={Ali, Muhammad Salman and Bae, Sung-Ho and Tartaglione, Enzo},
  year    = {2025},
  journal = {IEEE/CVF Winter Conference on Applications of Computer Vision},
  year={2025},
  selected = {true},
  pdf={https://openaccess.thecvf.com/content/WACV2025/html/Ali_ELMGS_Enhancing_Memory_and_Computation_Scalability_through_Compression_for_3D_WACV_2025_paper.html},
  preview={elmgs.png},
  code = {https://github.com/salmanali96/ELMGS},
  abstract={3D models have recently been popularized by the potentiality of end-to-end training offered first by Neural Radiance Fields and most recently by 3D Gaussian Splatting models. The latter has the big advantage of naturally providing fast training convergence and high editability. However as the research around these is still in its infancy there is still a gap in the literature regarding the model's scalability. In this work we propose an approach enabling both memory and computation scalability of such models. More specifically we propose an iterative pruning strategy that removes redundant information encoded in the model. We also enhance compressibility for the model by including a differentiable quantization and entropy coding estimator in the optimization strategy. Our results on popular benchmarks showcase the effectiveness of the proposed approach and open the road to the broad deployability of such a solution even on resource-constrained devices.}
}

@article{spadaro2024alice,
  abbr = {VCIP},
  title={ALICE: Adapt your Learnable Image Compression modEl for variable bitrates},
  author={Spadaro, Gabriele and Ali, Muhammad Salman and Presta, Alberto and Pilo, Giommaria and Bae, Sung-Ho and Giraldo, Jhony H and Fiandrotti, Attilio and Grangetto, Marco and Tartaglione, Enzo},
  journal={IEEE International Conference on Visual Communications and Image Processing (VCIP)},
  year={2024},
  organization={IEEE},
  selected = {true},
  pdf={https://ieeexplore.ieee.org/abstract/document/10849832},
  preview={alice.png},
  abstract={When training a Learned Image Compression model, the loss function is minimized such that the encoder and the decoder attain a target Rate-Distorsion trade-off. Therefore, a distinct model shall be trained and stored at the transmitter and receiver for each target rate, fostering the quest for efficient variable bitrate compression schemes. This paper proposes plugging Low-Rank Adapters into a transformer-based pre-trained LIC model and training them to meet different target rates. With our method, encoding an image at a variable rate is as simple as training the corresponding adapters and plugging them into the frozen pre-trained model. Our experiments show performance comparable with state-of-the-art fixed-rate LIC models at a fraction of the training and deployment cost. We publicly released the code at https://github.com/EIDOSLAB/ALICE.}
}

@article{Ali_2024_BMVC,
abbr = {BMVC},
author    = {Ali, Muhammad Salman and Maryam Qamar and Sung-Ho Bae and Enzo Tartaglione},
title     = {Trimming the Fat: Efficient Compression of 3D Gaussian Splats through Pruning},
journal = {British Machine Vision Conference 2024, BMVC 2024},
publisher = {BMVA},
year      = {2024},
selected = {true},
pdf       = {https://bmva-archive.org.uk/bmvc/2024/papers/Paper_358/paper.pdf},
preview={bmvc.png},
code = {https://github.com/salmanali96/trimming-the-fat},
video = {https://bmva-archive.org.uk/bmvc/2024/papers/Paper_358/video.mp4},
poster = {https://bmva-archive.org.uk/bmvc/2024/papers/Paper_358/poster.pdf}
}

@article{ali2023towards,
  abbr = {NeurIPS},
  title={Towards efficient image compression without autoregressive models},
  author={Ali, Muhammad Salman and Kim, Yeongwoong and Qamar, Maryam and Lim, Sung-Chang and Kim, Donghyun and Zhang, Chaoning and Bae, Sung-Ho and Kim, Hui Yong},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={7392--7404},
  year={2023},
  selected = {true},
  pdf={https://proceedings.neurips.cc/paper_files/paper/2023/hash/170dc3e41f2d03e327e04dbab0fccbfb-Abstract-Conference.html},
  preview={neurips.png},
  abstract={Recently, learned image compression (LIC) has garnered increasing interest with its rapidly improving performance surpassing conventional codecs. A key ingredient of LIC is a hyperprior-based entropy model, where the underlying joint probability of the latent image features is modeled as a product of Gaussian distributions from each latent element. Since latents from the actual images are not spatially independent, autoregressive (AR) context based entropy models were proposed to handle the discrepancy between the assumed distribution and the actual distribution. Though the AR-based models have proven effective, the computational complexity is significantly increased due to the inherent sequential nature of the algorithm. In this paper, we present a novel alternative to the AR-based approach that can provide a significantly better trade-off between performance and complexity. To minimize the discrepancy, we introduce a correlation loss that forces the latents to be spatially decorrelated and better fitted to the independent probability model. Our correlation loss is proved to act as a general plug-in for the hyperprior (HP) based learned image compression methods. The performance gain from our correlation loss is ‘free’ in terms of computation complexity for both inference time and decoding time. To our knowledge, our method gives the best trade-off between the complexity and performance: combined with the Checkerboard-CM, it attains 90% and when combined with ChARM-CM, it attains 98% of the AR-based BD-Rate gains yet is around 50 times and 30 times faster than AR-based methods respectively}
}

@inproceedings{kim2021distilling,
  abbr = {ICCV},
  title={Distilling global and local logits with densely connected relations},
  author={Kim, Youmin and Park, Jinbae and Jang, YounHo and Ali, Muhammad Salman and Oh, Tae-Hyun and Bae, Sung-Ho},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6290--6300},
  year={2021},
  selected = {true},
  pdf={https://openaccess.thecvf.com/content/ICCV2021/html/Kim_Distilling_Global_and_Local_Logits_With_Densely_Connected_Relations_ICCV_2021_paper.html},
  preview={iccv.png},
  abstract={In prevalent knowledge distillation, logits in most image recognition models are computed by global average pooling, then used to learn to encode the high-level and task-relevant knowledge. In this work, we solve the limitation of this global logit transfer in this distillation context. We point out that it prevents the transfer of informative spatial information, which provides localized knowledge as well as rich relational information across contexts of an input scene. To exploit the rich spatial information, we propose a simple yet effective logit distillation approach. We add a local spatial pooling layer branch to the penultimate layer, thereby our method extends the standard logit distillation and enables learning of both finely-localized knowledge and holistic representation. Our proposed method shows favorable accuracy improvement against the state-of-the-art methods on several image classification datasets. We show that our distilled students trained on the image classification task can be successfully leveraged for object detection and semantic segmentation tasks; this result demonstrates our method's high transferability.}

}
