<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Muhammad Salman Ali


</title>
<meta name="description" content="Personal website. 
">

<!-- Open Graph -->

<meta property="og:site_name" content="Personal website. 
" />
<meta property="og:type" content="object" />
<meta property="og:title" content="" />
<meta property="og:url" content="https://salmanali96.github.io//" />
<meta property="og:description" content="about" />
<meta property="og:image" content="" />


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->
<link rel="stylesheet" href="/assets/css/github.css">

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü§ñ</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SE0GC912HX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-SE0GC912HX');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="navbar-brand social">
          <a href="mailto:%73%61%6C%6D%61%6E%61%6C%69%38%39%36@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=qbreZUIAAAAJ&hl" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/salmanali96" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/muhammad-salman-ali-046a74125" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>











        </div>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          <!-- Blog Button -->
          <li class="nav-item">
            <a class="nav-link" href="https://drive.google.com/file/d/1JZbtwkH4cP5gd4o7vqToB6rth3vlC8u5/view?usp=sharing" target="_blank">
              üìùCV
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-3">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     Muhammad Salman Ali
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/IMG_0580.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <style>
.logos-container {
    display: flex;
    justify-content: center;
    flex-wrap: wrap;
    gap: 20px;
    margin-top: 20px;
}

.logo {
    width: 100%;
    max-width: 40px;
    height: auto;
    transition: all 0.3s ease-in-out;
}

/* Responsive adjustments */
@media (min-width: 540px) {
    .logo {
        max-width: 70px; 
    }
}

@media (min-width: 900px) {
    .logo {
        max-width: 80px;
    }
}

@media (max-width: 480px) {
    .logos-container {
        gap: 10px;
    }
    .logo {
        max-width: 45px;
    }
}
</style>

<p>I am a final-year Ph.D. student at Kyung Hee University, South Korea. I successfully defended my dissertation in June 2025 and currently seeking postdoctoral or research scientist positions.</p>

<p>I completed my bachelor‚Äôs in computer science (BSc) from National University of Sciences and Technology (NUST) Pakistan in 2018 with a distinction (gold medal). I began my MS‚ÄìPh.D. program under <a href="https://scholar.google.com/citations?user=EULut5oAAAAJ&amp;hl=en">Prof. Sung Ho Bae</a>, and have since had the privilege of working with <a href="https://scholar.google.com/citations?user=qbiBc50AAAAJ&amp;hl=en">Prof. Hui Yong Kim</a>, <a href="https://scholar.google.com/citations?user=lvhxhyQAAAAJ&amp;hl=en">Prof. Chaoning Zhang</a>, and <a href="https://scholar.google.com/citations?user=uKuvN64AAAAJ&amp;hl=en">Prof. Enzo Tartaglione</a>.</p>

<p>My research focuses on image compression and 3D Gaussian Splatting compression. I have published over <a href="https://scholar.google.com/citations?user=qbreZUIAAAAJ&amp;hl=en">20 papers</a>, including in top venues like NeurIPS, ICCV, BMVC, WACV, and about 7 SCIE-indexed journals.</p>

<p>Outside of research, I‚Äôm an avid cricket enthusiast and a passionate student of history.</p>

    </div>

    
      <div class="news">
  <h2>Updates</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Jun,&nbsp2025 </th> -->
             <th> &nbsp2025: </th>
            <td>
              
                Successfully defended my Ph.D. thesis.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> May,&nbsp2025 </th> -->
             <th> &nbsp2025: </th>
            <td>
              
                Our paper Iterative-INR is now available on <a href="https://arxiv.org/abs/2504.17364">arxiv</a>.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Feb,&nbsp2025 </th> -->
             <th> &nbsp2025: </th>
            <td>
              
                Our survey paper Compression in 3DGS: A Survey of Methods, Trends, and Future Directions is now available on <a href="https://arxiv.org/abs/2502.19457">arxiv</a>.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Dec,&nbsp2024 </th> -->
             <th> &nbsp2024: </th>
            <td>
              
                Our papers got published in <a href="https://openaccess.thecvf.com/content/WACV2025/papers/Ali_ELMGS_Enhancing_Memory_and_Computation_Scalability_through_Compression_for_3D_WACV_2025_paper.pdf">WACV</a>, <a href="https://bmvc2024.org/proceedings/358/">BMVC</a>, <a href="https://ieeexplore.ieee.org/abstract/document/10849832">IEEE VCIP</a>, and <a href="https://link.springer.com/article/10.1007/s11760-024-03559-6">SIVP</a>.
how

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Feb,&nbsp2024 </th> -->
             <th> &nbsp2024: </th>
            <td>
              
                Joined Multimedia Lab in Telecom Paris as a Ph.D. research intern.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Dec,&nbsp2023 </th> -->
             <th> &nbsp2023: </th>
            <td>
              
                Papers accepted in <a href="https://openreview.net/forum?id=HBEegN2HcR">NeurIPS workshop</a>, <a href="https://ieeexplore.ieee.org/abstract/document/10402755">IEEE VCIP</a>, and <a href="https://ieeexplore.ieee.org/abstract/document/10078247">IEEE Access</a>.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Sep,&nbsp2023 </th> -->
             <th> &nbsp2023: </th>
            <td>
              
                One <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/170dc3e41f2d03e327e04dbab0fccbfb-Abstract-Conference.html">paper</a> got accepted at the Neural Information Processing Systems - NeurIPS, 2023.


              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Dec,&nbsp2021 </th> -->
             <th> &nbsp2021: </th>
            <td>
              
                One paper accepted in <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Kim_Distilling_Global_and_Local_Logits_With_Densely_Connected_Relations_ICCV_2021_paper.html">ICCV</a>, 3 Papers accepted in IEEE Access and Journal of Broadcasting.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Jun,&nbsp2020 </th> -->
             <th> &nbsp2020: </th>
            <td>
              
                Paper published in <a href="https://ieeexplore.ieee.org/document/9169869">IEEE Access</a>.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Sep,&nbsp2018 </th> -->
             <th> &nbsp2018: </th>
            <td>
              
                Started as MS-Ph.D. graduate student at <a href="https://mlvc.khu.ac.kr">MLVC Lab</a>, Kyung Hee University, South Korea.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <!-- <th> Jun,&nbsp2018 </th> -->
             <th> &nbsp2018: </th>
            <td>
              
                Graduated in BS Computer Science from NUST with a Gold Medal.

              
            </td>
          </tr>
          
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Selected Publications</h2>
  <ol class="bibliography"><li><!-- <style>
.paper-image {
  float: left;
  margin-top: 5px;
  margin-right: 10px; /* Space between image and text */
  width: 80; /* Adjust size as needed */
  height: auto;
}
</style> -->

<div class="row">

  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge text-bg-secondary"><a href="http://arxiv.org" target="_blank">arXiv</a></abbr>
    
  
  <img class="paper-image" src="/assets/img/publication_preview/i-inr.png" alt="Paper Image">

  </div>


  <div id="haider2025inr" class="col-sm-9">
    
      <div class="title">I-INR: Iterative Implicit Neural Representations</div>
      <!-- <span class="robustness">Privacy & Security</span> -->
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Haider, Ali*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ali, Muhammad Salman*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Qamar, Maryam,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Khalil, Tahir,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kim, Soo Ye,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Oh, Jihyong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tartaglione, Enzo,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Bae, Sung-Ho
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Under Review (arXiv)</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/abs/2504.17364" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Implicit Neural Representations (INRs) have revolutionized signal processing and computer vision by modeling signals as continuous, differentiable functions parameterized by neural networks. However, their inherent formulation as a regression problem makes them prone to regression to the mean, limiting their ability to capture fine details, retain high-frequency information, and handle noise effectively. To address these challenges, we propose Iterative Implicit Neural Representations (I-INRs) a novel plug-and-play framework that enhances signal reconstruction through an iterative refinement process. I-INRs effectively recover high-frequency details, improve robustness to noise, and achieve superior reconstruction quality. Our framework seamlessly integrates with existing INR architectures, delivering substantial performance gains across various tasks. Extensive experiments show that I-INRs outperform baseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision applications such as image restoration, image denoising, and object occupancy prediction.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><!-- <style>
.paper-image {
  float: left;
  margin-top: 5px;
  margin-right: 10px; /* Space between image and text */
  width: 80; /* Adjust size as needed */
  height: auto;
}
</style> -->

<div class="row">

  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge text-bg-secondary"><a href="http://arxiv.org" target="_blank">arXiv</a></abbr>
    
  
  <img class="paper-image" src="/assets/img/publication_preview/3dgs_survey.png" alt="Paper Image">

  </div>


  <div id="ali2025compression" class="col-sm-9">
    
      <div class="title">Compression in 3d gaussian splatting: A survey of methods, trends, and future directions</div>
      <!-- <span class="robustness">Privacy & Security</span> -->
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ali, Muhammad Salman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhang, Chaoning,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Cagnazzo, Marco,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Valenzise, Giuseppe,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tartaglione, Enzo,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Bae, Sung-Ho
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Under Review (arXiv)</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/abs/2502.19457" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>3D Gaussian Splatting (3DGS) has recently emerged as a pioneering approach in explicit scene rendering and computer graphics. Unlike traditional neural radiance field (NeRF) methods, which typically rely on implicit, coordinate-based models to map spatial coordinates to pixel values, 3DGS utilizes millions of learnable 3D Gaussians. Its differentiable rendering technique and inherent capability for explicit scene representation and manipulation positions 3DGS as a potential game-changer for the next generation of 3D reconstruction and representation technologies. This enables 3DGS to deliver real-time rendering speeds while offering unparalleled editability levels. However, despite its advantages, 3DGS suffers from substantial memory and storage requirements, posing challenges for deployment on resource-constrained devices. In this survey, we provide a comprehensive overview focusing on the scalability and compression of 3DGS. We begin with a detailed background overview of 3DGS, followed by a structured taxonomy of existing compression methods. Additionally, we analyze and compare current methods from the topological perspective, evaluating their strengths and limitations in terms of fidelity, compression ratios, and computational efficiency. Furthermore, we explore how advancements in efficient NeRF representations can inspire future developments in 3DGS optimization. Finally, we conclude with current research challenges and highlight key directions for future exploration.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><!-- <style>
.paper-image {
  float: left;
  margin-top: 5px;
  margin-right: 10px; /* Space between image and text */
  width: 80; /* Adjust size as needed */
  height: auto;
}
</style> -->

<div class="row">

  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge text-bg-secondary"><a href="https://wacv2025.thecvf.com" target="_blank">WACV</a></abbr>
    
  
  <img class="paper-image" src="/assets/img/publication_preview/elmgs.png" alt="Paper Image">

  </div>


  <div id="ali2024elmgs" class="col-sm-9">
    
      <div class="title">ELMGS: Enhancing memory and computation scaLability through coMpression for 3D Gaussian Splatting</div>
      <!-- <span class="robustness">Privacy & Security</span> -->
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ali, Muhammad Salman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bae, Sung-Ho,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tartaglione, Enzo
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE/CVF Winter Conference on Applications of Computer Vision</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://openaccess.thecvf.com/content/WACV2025/html/Ali_ELMGS_Enhancing_Memory_and_Computation_Scalability_through_Compression_for_3D_WACV_2025_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/salmanali96/ELMGS" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>3D models have recently been popularized by the potentiality of end-to-end training offered first by Neural Radiance Fields and most recently by 3D Gaussian Splatting models. The latter has the big advantage of naturally providing fast training convergence and high editability. However as the research around these is still in its infancy there is still a gap in the literature regarding the model‚Äôs scalability. In this work we propose an approach enabling both memory and computation scalability of such models. More specifically we propose an iterative pruning strategy that removes redundant information encoded in the model. We also enhance compressibility for the model by including a differentiable quantization and entropy coding estimator in the optimization strategy. Our results on popular benchmarks showcase the effectiveness of the proposed approach and open the road to the broad deployability of such a solution even on resource-constrained devices.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><!-- <style>
.paper-image {
  float: left;
  margin-top: 5px;
  margin-right: 10px; /* Space between image and text */
  width: 80; /* Adjust size as needed */
  height: auto;
}
</style> -->

<div class="row">

  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge text-bg-secondary">VCIP</abbr> 
    
  
  <img class="paper-image" src="/assets/img/publication_preview/alice.png" alt="Paper Image">

  </div>


  <div id="spadaro2024alice" class="col-sm-9">
    
      <div class="title">ALICE: Adapt your Learnable Image Compression modEl for variable bitrates</div>
      <!-- <span class="robustness">Privacy & Security</span> -->
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Spadaro, Gabriele,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ali, Muhammad Salman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Presta, Alberto,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Pilo, Giommaria,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bae, Sung-Ho,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Giraldo, Jhony H,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fiandrotti, Attilio,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Grangetto, Marco,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tartaglione, Enzo
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE International Conference on Visual Communications and Image Processing (VCIP)</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/abstract/document/10849832" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>When training a Learned Image Compression model, the loss function is minimized such that the encoder and the decoder attain a target Rate-Distorsion trade-off. Therefore, a distinct model shall be trained and stored at the transmitter and receiver for each target rate, fostering the quest for efficient variable bitrate compression schemes. This paper proposes plugging Low-Rank Adapters into a transformer-based pre-trained LIC model and training them to meet different target rates. With our method, encoding an image at a variable rate is as simple as training the corresponding adapters and plugging them into the frozen pre-trained model. Our experiments show performance comparable with state-of-the-art fixed-rate LIC models at a fraction of the training and deployment cost. We publicly released the code at https://github.com/EIDOSLAB/ALICE.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><!-- <style>
.paper-image {
  float: left;
  margin-top: 5px;
  margin-right: 10px; /* Space between image and text */
  width: 80; /* Adjust size as needed */
  height: auto;
}
</style> -->

<div class="row">

  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge text-bg-secondary">BMVC</abbr> 
    
  
  <img class="paper-image" src="/assets/img/publication_preview/bmvc.png" alt="Paper Image">

  </div>


  <div id="Ali_2024_BMVC" class="col-sm-9">
    
      <div class="title">Trimming the Fat: Efficient Compression of 3D Gaussian Splats through Pruning</div>
      <!-- <span class="robustness">Privacy & Security</span> -->
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ali, Muhammad Salman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Qamar, Maryam,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bae, Sung-Ho,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tartaglione, Enzo
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>British Machine Vision Conference 2024, BMVC 2024</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_358/paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/salmanali96/trimming-the-fat" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_358/poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
      
      <a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_358/video.mp4" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><!-- <style>
.paper-image {
  float: left;
  margin-top: 5px;
  margin-right: 10px; /* Space between image and text */
  width: 80; /* Adjust size as needed */
  height: auto;
}
</style> -->

<div class="row">

  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge text-bg-secondary"><a href="https://neurips.cc" target="_blank">NeurIPS</a></abbr>
    
  
  <img class="paper-image" src="/assets/img/publication_preview/neurips.png" alt="Paper Image">

  </div>


  <div id="ali2023towards" class="col-sm-9">
    
      <div class="title">Towards efficient image compression without autoregressive models</div>
      <!-- <span class="robustness">Privacy & Security</span> -->
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ali, Muhammad Salman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kim, Yeongwoong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Qamar, Maryam,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lim, Sung-Chang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kim, Donghyun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhang, Chaoning,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bae, Sung-Ho,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kim, Hui Yong
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Advances in Neural Information Processing Systems</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/170dc3e41f2d03e327e04dbab0fccbfb-Abstract-Conference.html" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recently, learned image compression (LIC) has garnered increasing interest with its rapidly improving performance surpassing conventional codecs. A key ingredient of LIC is a hyperprior-based entropy model, where the underlying joint probability of the latent image features is modeled as a product of Gaussian distributions from each latent element. Since latents from the actual images are not spatially independent, autoregressive (AR) context based entropy models were proposed to handle the discrepancy between the assumed distribution and the actual distribution. Though the AR-based models have proven effective, the computational complexity is significantly increased due to the inherent sequential nature of the algorithm. In this paper, we present a novel alternative to the AR-based approach that can provide a significantly better trade-off between performance and complexity. To minimize the discrepancy, we introduce a correlation loss that forces the latents to be spatially decorrelated and better fitted to the independent probability model. Our correlation loss is proved to act as a general plug-in for the hyperprior (HP) based learned image compression methods. The performance gain from our correlation loss is ‚Äòfree‚Äô in terms of computation complexity for both inference time and decoding time. To our knowledge, our method gives the best trade-off between the complexity and performance: combined with the Checkerboard-CM, it attains 90% and when combined with ChARM-CM, it attains 98% of the AR-based BD-Rate gains yet is around 50 times and 30 times faster than AR-based methods respectively</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><!-- <style>
.paper-image {
  float: left;
  margin-top: 5px;
  margin-right: 10px; /* Space between image and text */
  width: 80; /* Adjust size as needed */
  height: auto;
}
</style> -->

<div class="row">

  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge text-bg-secondary"><a href="https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings" target="_blank">ICCV</a></abbr>
    
  
  <img class="paper-image" src="/assets/img/publication_preview/iccv.png" alt="Paper Image">

  </div>


  <div id="kim2021distilling" class="col-sm-9">
    
      <div class="title">Distilling global and local logits with densely connected relations</div>
      <!-- <span class="robustness">Privacy & Security</span> -->
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Kim, Youmin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Park, Jinbae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jang, YounHo,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ali, Muhammad Salman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Oh, Tae-Hyun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Bae, Sung-Ho
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Kim_Distilling_Global_and_Local_Logits_With_Densely_Connected_Relations_ICCV_2021_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In prevalent knowledge distillation, logits in most image recognition models are computed by global average pooling, then used to learn to encode the high-level and task-relevant knowledge. In this work, we solve the limitation of this global logit transfer in this distillation context. We point out that it prevents the transfer of informative spatial information, which provides localized knowledge as well as rich relational information across contexts of an input scene. To exploit the rich spatial information, we propose a simple yet effective logit distillation approach. We add a local spatial pooling layer branch to the penultimate layer, thereby our method extends the standard logit distillation and enables learning of both finely-localized knowledge and holistic representation. Our proposed method shows favorable accuracy improvement against the state-of-the-art methods on several image classification datasets. We show that our distilled students trained on the image classification task can be successfully leveraged for object detection and semantic segmentation tasks; this result demonstrates our method‚Äôs high transferability.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
</div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2025 Muhammad Salman  Ali.
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
